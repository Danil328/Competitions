{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/mlboot_dataset/'\n",
    "model_name = 'nt5'\n",
    "results_dir = './results/'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import scipy.sparse as sp\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609018, 2053602) (609018, 2812610) (609018, 1057788)\n",
      "(609018, 598456) (609018, 20275) (609018, 92738)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir + 'preprocessed.csv') \n",
    "y = pd.read_table(data_dir + 'mlboot_train_answers.tsv')\n",
    "y.columns = ['uid','target']\n",
    "df = df.merge(y, on='uid', how='left')\n",
    "\n",
    "mat1 = sp.load_npz(data_dir+'dmat1.npz').tolil()\n",
    "mat2 = sp.load_npz(data_dir+'dmat2.npz').tolil()\n",
    "mat3 = sp.load_npz(data_dir+'dmat3.npz').tolil()\n",
    "print(mat1.shape, mat2.shape, mat3.shape)\n",
    "\n",
    "df['max_f1'] = mat1.tocsr().max(axis=1).todense()\n",
    "df['max_f2'] = mat2.tocsr().max(axis=1).todense()\n",
    "df['max_f3'] = mat3.tocsr().max(axis=1).todense()\n",
    "\n",
    "limit = 4\n",
    "mat1 = mat1.tocsc()[:, np.where(mat1.getnnz(axis=0) > limit)[0]].tocsr()\n",
    "mat2 = mat2.tocsc()[:, np.where(mat2.getnnz(axis=0) > limit)[0]].tocsr()\n",
    "mat3 = mat3.tocsc()[:, np.where(mat3.getnnz(axis=0) > limit)[0]].tocsr()\n",
    "print(mat1.shape, mat2.shape, mat3.shape)\n",
    "\n",
    "df_train_index = df[~df.target.isnull()].index\n",
    "df_test_index = df[df.target.isnull()].index\n",
    "\n",
    "train_mat1 = mat1[df_train_index.tolist()]\n",
    "test_mat1 = mat1[df_test_index.tolist()]\n",
    "train_mat2 = mat2[df_train_index.tolist()]\n",
    "test_mat2 = mat2[df_test_index.tolist()]\n",
    "train_mat3 = mat3[df_train_index.tolist()]\n",
    "test_mat3 = mat3[df_test_index.tolist()]\n",
    "\n",
    "del mat1,mat2,mat3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['most_freq_cat'] = np.argmax(df[[u'num_times_cat_eq_0', u'num_times_cat_eq_1',\n",
    "       u'num_times_cat_eq_2', u'num_times_cat_eq_3', u'num_times_cat_eq_4',\n",
    "       u'num_times_cat_eq_5']].fillna(0).values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[~df.target.isnull(),:].reset_index(drop=True)\n",
    "x_te = df.loc[df.target.isnull(),:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.626105242626\n",
      "fold 1\n",
      "1 0.609323199151\n",
      "fold 2\n",
      "2 0.608542823781\n",
      "fold 3\n",
      "3 0.616122329507\n",
      "fold 4\n",
      "4 0.61329483061\n",
      "fold 5\n",
      "5 0.626851899506\n",
      "fold 6\n",
      "6 0.619582901644\n",
      "fold 7\n",
      "7 0.617508361161\n",
      "fold 8\n",
      "8 0.624439639139\n",
      "fold 9\n",
      "9 0.615391426295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge,SGDRegressor\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=239)\n",
    "\n",
    "ifold = 0\n",
    "\n",
    "y_ridge_pred1 = 0\n",
    "y_ridge_oof1 = X[['uid','target']].copy()\n",
    "y_ridge_oof1['target'] = np.nan\n",
    "\n",
    "for train_index,test_index in kf.split(X):\n",
    "    print('fold', ifold)\n",
    "    \n",
    "    y_tr,y_va = X.loc[train_index,'target'].values,X.loc[test_index,'target'].values\n",
    "    X_tr = train_mat2[train_index]\n",
    "    X_va = train_mat2[test_index]\n",
    "    X_te = test_mat2\n",
    "    \n",
    "    model = Ridge(max_iter=12)\n",
    "    model.fit(X_tr,y_tr)\n",
    "    \n",
    "    yhat = model.predict(X_va)\n",
    "    print(ifold,roc_auc_score(y_va,yhat))\n",
    "    y_ridge_oof1.loc[test_index,'target'] = yhat\n",
    "\n",
    "    ytst = model.predict(X_te)\n",
    "    y_ridge_pred1 += ytst*0.1\n",
    "    \n",
    "    ifold += 1\n",
    "X['ridge2'] = y_ridge_oof1.target.values\n",
    "x_te['ridge2'] = y_ridge_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['diff_num_cats'] = (X['num_times_cat_eq_0']>0).astype(np.int32)+(X['num_times_cat_eq_1']>0).astype(np.int32)+\\\n",
    "(X['num_times_cat_eq_2']>0).astype(np.int32)+(X['num_times_cat_eq_3']>0).astype(np.int32)+\\\n",
    "(X['num_times_cat_eq_4']>0).astype(np.int32)+(X['num_times_cat_eq_5']>0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te['diff_num_cats'] = (x_te['num_times_cat_eq_0']>0).astype(np.int32)+(x_te['num_times_cat_eq_1']>0).astype(np.int32)+\\\n",
    "(x_te['num_times_cat_eq_2']>0).astype(np.int32)+(x_te['num_times_cat_eq_3']>0).astype(np.int32)+\\\n",
    "(x_te['num_times_cat_eq_4']>0).astype(np.int32)+(x_te['num_times_cat_eq_5']>0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "sample_sub = pd.read_table(data_dir+'mlboot_test.tsv')\n",
    "sample_sub['target'] = minmax_scale(np.load(results_dir + 'test_nn_base_model.npy'))\n",
    "sample_sub.columns = ['uid','nnet']\n",
    "x_te = x_te.merge(sample_sub, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_table(data_dir+'mlboot_test.tsv')\n",
    "sample_sub['target'] = minmax_scale(np.load(results_dir + 'test_baseline_sparse_10folds.npy'))\n",
    "sample_sub.columns = ['uid','lgbm1']\n",
    "x_te = x_te.merge(sample_sub, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_table(data_dir+'mlboot_test.tsv')\n",
    "sample_sub['target'] = minmax_scale(np.load(results_dir + 'test_all_in_focal_loss.npy'))\n",
    "sample_sub.columns = ['uid','nnet2']\n",
    "x_te = x_te.merge(sample_sub, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_table(data_dir+'mlboot_test.tsv')\n",
    "sample_sub['target'] = minmax_scale(np.load(results_dir + 'test_focal_loss_m3.npy'))\n",
    "sample_sub.columns = ['uid','nnet3']\n",
    "x_te = x_te.merge(sample_sub, on='uid', how='left')\n",
    "sample_sub = pd.read_table(data_dir+'mlboot_test.tsv')\n",
    "sample_sub['target'] = minmax_scale(np.load(results_dir + 'test_focal_loss_m1.npy'))\n",
    "sample_sub.columns = ['uid','nnet1']\n",
    "x_te = x_te.merge(sample_sub, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['lgbm1'] = minmax_scale(np.load(results_dir + 'train_baseline_sparse_10folds.npy'))\n",
    "X['nnet'] = minmax_scale(np.load(results_dir + 'train_nn_base_model.npy'))\n",
    "X['nnet2'] = minmax_scale(np.load(results_dir + 'train_all_in_focal_loss.npy'))\n",
    "X['nnet1'] = minmax_scale(np.load(results_dir + 'train_focal_loss_m1.npy'))\n",
    "X['nnet3'] = minmax_scale(np.load(results_dir + 'train_focal_loss_m3.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nnet</th>\n",
       "      <th>lgbm1</th>\n",
       "      <th>nnet2</th>\n",
       "      <th>nnet1</th>\n",
       "      <th>nnet3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nnet</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.681589</td>\n",
       "      <td>0.753490</td>\n",
       "      <td>0.488332</td>\n",
       "      <td>0.330658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm1</th>\n",
       "      <td>0.681589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593723</td>\n",
       "      <td>0.536187</td>\n",
       "      <td>0.342257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet2</th>\n",
       "      <td>0.753490</td>\n",
       "      <td>0.593723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.582909</td>\n",
       "      <td>0.353475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet1</th>\n",
       "      <td>0.488332</td>\n",
       "      <td>0.536187</td>\n",
       "      <td>0.582909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet3</th>\n",
       "      <td>0.330658</td>\n",
       "      <td>0.342257</td>\n",
       "      <td>0.353475</td>\n",
       "      <td>0.488963</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nnet     lgbm1     nnet2     nnet1     nnet3\n",
       "nnet   1.000000  0.681589  0.753490  0.488332  0.330658\n",
       "lgbm1  0.681589  1.000000  0.593723  0.536187  0.342257\n",
       "nnet2  0.753490  0.593723  1.000000  0.582909  0.353475\n",
       "nnet1  0.488332  0.536187  0.582909  1.000000  0.488963\n",
       "nnet3  0.330658  0.342257  0.353475  0.488963  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_te[['nnet','lgbm1','nnet2','nnet1','nnet3']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm1</th>\n",
       "      <th>nnet</th>\n",
       "      <th>nnet2</th>\n",
       "      <th>nnet1</th>\n",
       "      <th>nnet3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgbm1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664970</td>\n",
       "      <td>0.570985</td>\n",
       "      <td>0.494446</td>\n",
       "      <td>0.295207</td>\n",
       "      <td>0.170409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet</th>\n",
       "      <td>0.664970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659126</td>\n",
       "      <td>0.460005</td>\n",
       "      <td>0.289962</td>\n",
       "      <td>0.130658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet2</th>\n",
       "      <td>0.570985</td>\n",
       "      <td>0.659126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.548694</td>\n",
       "      <td>0.312146</td>\n",
       "      <td>0.111062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet1</th>\n",
       "      <td>0.494446</td>\n",
       "      <td>0.460005</td>\n",
       "      <td>0.548694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487426</td>\n",
       "      <td>0.091230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet3</th>\n",
       "      <td>0.295207</td>\n",
       "      <td>0.289962</td>\n",
       "      <td>0.312146</td>\n",
       "      <td>0.487426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.170409</td>\n",
       "      <td>0.130658</td>\n",
       "      <td>0.111062</td>\n",
       "      <td>0.091230</td>\n",
       "      <td>0.049012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lgbm1      nnet     nnet2     nnet1     nnet3    target\n",
       "lgbm1   1.000000  0.664970  0.570985  0.494446  0.295207  0.170409\n",
       "nnet    0.664970  1.000000  0.659126  0.460005  0.289962  0.130658\n",
       "nnet2   0.570985  0.659126  1.000000  0.548694  0.312146  0.111062\n",
       "nnet1   0.494446  0.460005  0.548694  1.000000  0.487426  0.091230\n",
       "nnet3   0.295207  0.289962  0.312146  0.487426  1.000000  0.049012\n",
       "target  0.170409  0.130658  0.111062  0.091230  0.049012  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['lgbm1','nnet','nnet2','nnet1','nnet3','target']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.682562603224\n",
      "0.648537598744\n",
      "0.649222662589\n",
      "0.623698784984\n",
      "0.574520607881\n"
     ]
    }
   ],
   "source": [
    "for f in ['lgbm1','nnet','nnet2','nnet1','nnet3']:\n",
    "    print(roc_auc_score(X.target, X[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['ridge1'] = np.load(results_dir + 'train_ridge1.npy')\n",
    "x_te['ridge1'] = np.load(results_dir + 'test_ridge1.npy')\n",
    "X['ridge3'] = np.load(results_dir + 'train_ridge3.npy')\n",
    "x_te['ridge3'] = np.load(results_dir + 'test_ridge3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "0 lgbm 0.696430153644\n",
      "0 nn 0.664470244549\n",
      "0 nn2 0.669799660145\n",
      "0 nn1 0.62858143074\n",
      "0 nn3 0.578370888983\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.690582\tvalid_1's auc: 0.702004\n",
      "[200]\ttraining's auc: 0.692581\tvalid_1's auc: 0.702801\n",
      "[300]\ttraining's auc: 0.694626\tvalid_1's auc: 0.703148\n",
      "[400]\ttraining's auc: 0.696758\tvalid_1's auc: 0.70314\n",
      "[500]\ttraining's auc: 0.698755\tvalid_1's auc: 0.702994\n",
      "[600]\ttraining's auc: 0.700608\tvalid_1's auc: 0.702776\n",
      "Early stopping, best iteration is:\n",
      "[318]\ttraining's auc: 0.694971\tvalid_1's auc: 0.703193\n",
      "0 0.703193226062\n",
      "prepare test\n",
      "fold 1\n",
      "1 lgbm 0.679540369801\n",
      "1 nn 0.642941694898\n",
      "1 nn2 0.642705688137\n",
      "1 nn1 0.614755310425\n",
      "1 nn3 0.570227112295\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.692755\tvalid_1's auc: 0.681383\n",
      "[200]\ttraining's auc: 0.694785\tvalid_1's auc: 0.682428\n",
      "[300]\ttraining's auc: 0.696682\tvalid_1's auc: 0.682943\n",
      "[400]\ttraining's auc: 0.698707\tvalid_1's auc: 0.683321\n",
      "[500]\ttraining's auc: 0.700595\tvalid_1's auc: 0.683585\n",
      "[600]\ttraining's auc: 0.702408\tvalid_1's auc: 0.683744\n",
      "[700]\ttraining's auc: 0.704072\tvalid_1's auc: 0.683925\n",
      "[800]\ttraining's auc: 0.705786\tvalid_1's auc: 0.684\n",
      "[900]\ttraining's auc: 0.707495\tvalid_1's auc: 0.683982\n",
      "[1000]\ttraining's auc: 0.709148\tvalid_1's auc: 0.683964\n",
      "[1100]\ttraining's auc: 0.710812\tvalid_1's auc: 0.683849\n",
      "Early stopping, best iteration is:\n",
      "[837]\ttraining's auc: 0.706419\tvalid_1's auc: 0.684053\n",
      "1 0.684053238541\n",
      "prepare test\n",
      "fold 2\n",
      "2 lgbm 0.668976510596\n",
      "2 nn 0.631308787093\n",
      "2 nn2 0.639032546545\n",
      "2 nn1 0.617566495623\n",
      "2 nn3 0.569127792597\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.693727\tvalid_1's auc: 0.67359\n",
      "[200]\ttraining's auc: 0.695729\tvalid_1's auc: 0.673939\n",
      "[300]\ttraining's auc: 0.6977\tvalid_1's auc: 0.674501\n",
      "[400]\ttraining's auc: 0.699776\tvalid_1's auc: 0.674697\n",
      "[500]\ttraining's auc: 0.70162\tvalid_1's auc: 0.674959\n",
      "[600]\ttraining's auc: 0.703384\tvalid_1's auc: 0.675079\n",
      "[700]\ttraining's auc: 0.705152\tvalid_1's auc: 0.675014\n",
      "[800]\ttraining's auc: 0.706973\tvalid_1's auc: 0.674974\n",
      "Early stopping, best iteration is:\n",
      "[595]\ttraining's auc: 0.703274\tvalid_1's auc: 0.67511\n",
      "2 0.675109961918\n",
      "prepare test\n",
      "fold 3\n",
      "3 lgbm 0.687535579033\n",
      "3 nn 0.653121123282\n",
      "3 nn2 0.658701265405\n",
      "3 nn1 0.630450357451\n",
      "3 nn3 0.56938930191\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.691606\tvalid_1's auc: 0.694007\n",
      "[200]\ttraining's auc: 0.693609\tvalid_1's auc: 0.69457\n",
      "[300]\ttraining's auc: 0.695526\tvalid_1's auc: 0.694856\n",
      "[400]\ttraining's auc: 0.69758\tvalid_1's auc: 0.694805\n",
      "[500]\ttraining's auc: 0.699536\tvalid_1's auc: 0.694926\n",
      "[600]\ttraining's auc: 0.701261\tvalid_1's auc: 0.694883\n",
      "[700]\ttraining's auc: 0.703055\tvalid_1's auc: 0.694834\n",
      "[800]\ttraining's auc: 0.704811\tvalid_1's auc: 0.694713\n",
      "Early stopping, best iteration is:\n",
      "[508]\ttraining's auc: 0.699679\tvalid_1's auc: 0.694936\n",
      "3 0.694936121237\n",
      "prepare test\n",
      "fold 4\n",
      "4 lgbm 0.677337157284\n",
      "4 nn 0.651410532553\n",
      "4 nn2 0.648710895235\n",
      "4 nn1 0.623942068383\n",
      "4 nn3 0.571877207956\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.692787\tvalid_1's auc: 0.68326\n",
      "[200]\ttraining's auc: 0.694761\tvalid_1's auc: 0.683805\n",
      "[300]\ttraining's auc: 0.696812\tvalid_1's auc: 0.683876\n",
      "[400]\ttraining's auc: 0.698904\tvalid_1's auc: 0.683882\n",
      "[500]\ttraining's auc: 0.700811\tvalid_1's auc: 0.683843\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's auc: 0.695949\tvalid_1's auc: 0.68399\n",
      "4 0.683990080578\n",
      "prepare test\n",
      "fold 5\n",
      "5 lgbm 0.681785172531\n",
      "5 nn 0.652877919901\n",
      "5 nn2 0.660666201466\n",
      "5 nn1 0.632084253038\n",
      "5 nn3 0.583494111195\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.692214\tvalid_1's auc: 0.68914\n",
      "[200]\ttraining's auc: 0.694309\tvalid_1's auc: 0.688787\n",
      "[300]\ttraining's auc: 0.696424\tvalid_1's auc: 0.688607\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.690407\tvalid_1's auc: 0.689345\n",
      "5 0.689344707124\n",
      "prepare test\n",
      "fold 6\n",
      "6 lgbm 0.678971051709\n",
      "6 nn 0.65218096819\n",
      "6 nn2 0.650467721384\n",
      "6 nn1 0.623680152223\n",
      "6 nn3 0.57615678011\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.692612\tvalid_1's auc: 0.68427\n",
      "[200]\ttraining's auc: 0.694481\tvalid_1's auc: 0.684944\n",
      "[300]\ttraining's auc: 0.696474\tvalid_1's auc: 0.685229\n",
      "[400]\ttraining's auc: 0.69862\tvalid_1's auc: 0.685131\n",
      "[500]\ttraining's auc: 0.700646\tvalid_1's auc: 0.685105\n",
      "Early stopping, best iteration is:\n",
      "[296]\ttraining's auc: 0.696374\tvalid_1's auc: 0.685243\n",
      "6 0.685242726227\n",
      "prepare test\n",
      "fold 7\n",
      "7 lgbm 0.688371129106\n",
      "7 nn 0.658493141977\n",
      "7 nn2 0.661198575285\n",
      "7 nn1 0.632178151947\n",
      "7 nn3 0.582921097693\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.691409\tvalid_1's auc: 0.69295\n",
      "[200]\ttraining's auc: 0.693427\tvalid_1's auc: 0.693855\n",
      "[300]\ttraining's auc: 0.695506\tvalid_1's auc: 0.693818\n",
      "[400]\ttraining's auc: 0.697539\tvalid_1's auc: 0.693946\n",
      "[500]\ttraining's auc: 0.699459\tvalid_1's auc: 0.694146\n",
      "[600]\ttraining's auc: 0.701063\tvalid_1's auc: 0.694305\n",
      "[700]\ttraining's auc: 0.702829\tvalid_1's auc: 0.694319\n",
      "[800]\ttraining's auc: 0.704642\tvalid_1's auc: 0.694486\n",
      "[900]\ttraining's auc: 0.70642\tvalid_1's auc: 0.694346\n",
      "[1000]\ttraining's auc: 0.708172\tvalid_1's auc: 0.694439\n",
      "Early stopping, best iteration is:\n",
      "[789]\ttraining's auc: 0.704444\tvalid_1's auc: 0.694505\n",
      "7 0.694505469474\n",
      "prepare test\n",
      "fold 8\n",
      "8 lgbm 0.679418475164\n",
      "8 nn 0.646457711097\n",
      "8 nn2 0.652208047343\n",
      "8 nn1 0.624002984997\n",
      "8 nn3 0.576881638509\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.691948\tvalid_1's auc: 0.686663\n",
      "[200]\ttraining's auc: 0.694052\tvalid_1's auc: 0.68809\n",
      "[300]\ttraining's auc: 0.6961\tvalid_1's auc: 0.688625\n",
      "[400]\ttraining's auc: 0.698136\tvalid_1's auc: 0.688814\n",
      "[500]\ttraining's auc: 0.699949\tvalid_1's auc: 0.68848\n",
      "[600]\ttraining's auc: 0.701577\tvalid_1's auc: 0.688054\n",
      "[700]\ttraining's auc: 0.703239\tvalid_1's auc: 0.687832\n",
      "Early stopping, best iteration is:\n",
      "[408]\ttraining's auc: 0.698304\tvalid_1's auc: 0.688842\n",
      "8 0.6888420873\n",
      "prepare test\n",
      "fold 9\n",
      "9 lgbm 0.688222965672\n",
      "9 nn 0.646355690825\n",
      "9 nn2 0.646682807981\n",
      "9 nn1 0.624554841217\n",
      "9 nn3 0.585869737322\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's auc: 0.69201\tvalid_1's auc: 0.689493\n",
      "[200]\ttraining's auc: 0.693869\tvalid_1's auc: 0.690418\n",
      "[300]\ttraining's auc: 0.695777\tvalid_1's auc: 0.691233\n",
      "[400]\ttraining's auc: 0.697834\tvalid_1's auc: 0.691033\n",
      "[500]\ttraining's auc: 0.699801\tvalid_1's auc: 0.690757\n",
      "[600]\ttraining's auc: 0.701572\tvalid_1's auc: 0.690674\n",
      "Early stopping, best iteration is:\n",
      "[316]\ttraining's auc: 0.696085\tvalid_1's auc: 0.691307\n",
      "9 0.691306558571\n",
      "prepare test\n"
     ]
    }
   ],
   "source": [
    "def save_submit(model_name, folds, y_pred):\n",
    "    global x_te\n",
    "    sub = x_te[['uid','target']].copy()\n",
    "    sub['target'] = y_pred\n",
    "    sub.columns = ['cuid','target']\n",
    "    sample_sub = pd.read_table(data_dir+'mlboot_test.tsv')\n",
    "    sample_sub = sample_sub.merge(sub, on='cuid', how='left')\n",
    "    sample_sub[['target']].to_csv(results_dir + model_name + '_' + str(folds) + 'folds.csv', header=False, index=False)\n",
    "    del sub,sample_sub\n",
    "    gc.collect()\n",
    "    \n",
    "def mean_encode_test(df, y, test,k,column):\n",
    "    mean_0 = np.zeros((test.shape[0],1))\n",
    "    df['target'] = y\n",
    "    m0 = np.mean(y)  \n",
    "    y0s = df[['target',column]].groupby(column).agg(np.mean).reset_index()\n",
    "    y0s.columns = [column,'target_mean']\n",
    "    vc = df[column].value_counts().reset_index()\n",
    "    vc.columns = [column,'counts']\n",
    "    test = test.merge(y0s, on = column,how= 'left').merge(vc, on = column,how= 'left')\n",
    "    test['mean_target'] = (test.target_mean * test.counts + k * m0)/(test.counts + k)\n",
    "    mean_0 = np.array(test['mean_target']).reshape(-1,1)\n",
    "    return mean_0    \n",
    "\n",
    "def mean_encode_self(df, y, kf, k, column):\n",
    "    mean_0 = np.zeros((y.shape[0],1))\n",
    "    df['target'] = y\n",
    "    m0 = np.mean(y)\n",
    "    for dev_index, val_index in kf: \n",
    "        dev_X, val_X = df.iloc[dev_index,:], df.iloc[val_index,:]\n",
    "        y0s = dev_X[['target',column]].groupby(column).agg(np.mean).reset_index()\n",
    "        y0s.columns = [column,'target_mean']\n",
    "        vc = dev_X[column].value_counts().reset_index()\n",
    "        vc.columns = [column,'counts']\n",
    "        val_X = val_X.merge(y0s, on = column,how= 'left').merge(vc, on = column,how= 'left')\n",
    "        val_X['mean_target'] = (val_X.target_mean * val_X.counts + k * m0)/(val_X.counts + k)\n",
    "        mean_0[val_index,:] = np.array(val_X['mean_target']).reshape(-1,1)       \n",
    "    return mean_0\n",
    "\n",
    "def make_agg_features(X, train_index, test_index, test_data):\n",
    "    te_cols = ['most_freq_cat']\n",
    "    kf = KFold(n_splits = 5, random_state=2018, shuffle=True)\n",
    "    for c in te_cols:\n",
    "        X.loc[test_index,c + '_te'] = mean_encode_test(X.loc[train_index,:].copy(), X.loc[train_index,'target'].copy(), X.loc[test_index,:].copy(), 10.0, c)\n",
    "        test_data.loc[:,c + '_te'] = mean_encode_test(X.loc[train_index,:].copy(), X.loc[train_index,'target'].copy(), test_data.copy(), 10.0, c)\n",
    "        X.loc[train_index,c + '_te'] = mean_encode_self(X.loc[train_index,:].copy(), X.loc[train_index,'target'].copy(), kf.split(X.loc[train_index,:]), 10.0, c)\n",
    "    return X.loc[train_index,:], X.loc[test_index,:], test_data\n",
    "    \n",
    "train_cols = [u'num_keys_f1', 'max_f1', 'max_f2', 'max_f3', 'diff_num_cats',\n",
    "       u'sum_values_f1', u'num_keys_f2', u'sum_values_f2', u'num_keys_f3',\n",
    "       u'sum_values_f3', u'num_times_cat_eq_0', u'num_times_cat_eq_1',\n",
    "       u'num_times_cat_eq_2', u'num_times_cat_eq_3', u'num_times_cat_eq_4',\n",
    "       u'num_times_cat_eq_5', u'records', u'max_days', u'min_days',\n",
    "       u'sum_values_f1_std', u'num_keys_f1_std', u'sum_values_f2_std',\n",
    "       u'num_keys_f2_std', u'sum_values_f3_std', u'num_keys_f3_std',\n",
    "       u'sum_values_f1_max', u'num_keys_f1_max', u'sum_values_f2_max',\n",
    "       u'num_keys_f2_max', u'sum_values_f3_max', u'num_keys_f3_max',\n",
    "       u'sum_values_f1_mean', u'num_keys_f1_mean', u'sum_values_f2_mean',\n",
    "       u'num_keys_f2_mean', u'sum_values_f3_mean', u'num_keys_f3_mean', \n",
    "       'nnet','lgbm1','nnet2','nnet1','nnet3','most_freq_cat_te',\n",
    "       'ridge1','ridge3','ridge2']\n",
    "\n",
    "\n",
    "# Train the model\n",
    "parameters = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 16,\n",
    "    'max_depth' : 4,\n",
    "    'min_data' : 30,\n",
    "    #'lambda_l2' : 1.5,\n",
    "    'min_sum_hessian_in_leaf' : 0.1,\n",
    "    #'lambda_l1' : 0.2,\n",
    "    'is_unbalance': True,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.7,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=239)\n",
    "\n",
    "ifold = 0\n",
    "\n",
    "y_pred = 0\n",
    "y_oof = X[['uid','target']].copy()\n",
    "y_oof['target'] = np.nan\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index,test_index in kf.split(X):\n",
    "    print('fold', ifold)\n",
    "       \n",
    "    y_tr,y_va = X.loc[train_index,'target'].values,X.loc[test_index,'target'].values\n",
    "    X_tr,X_va,X_te = make_agg_features(X,train_index,test_index,x_te)\n",
    "    X_tr = X_tr[train_cols]\n",
    "    X_va = X_va[train_cols]\n",
    "    X_te = X_te[train_cols]\n",
    " \n",
    "\n",
    "    print(ifold,'lgbm',roc_auc_score(y_va,X.loc[test_index, :].lgbm1))\n",
    "    print(ifold,'nn',roc_auc_score(y_va,X.loc[test_index, :].nnet))\n",
    "    print(ifold,'nn2',roc_auc_score(y_va,X.loc[test_index, :].nnet2))\n",
    "    print(ifold,'nn1',roc_auc_score(y_va,X.loc[test_index, :].nnet1))\n",
    "    print(ifold,'nn3',roc_auc_score(y_va,X.loc[test_index, :].nnet3))\n",
    "       \n",
    "    # Create the LightGBM data containers\n",
    "    tr_data = lgb.Dataset(X_tr, label=y_tr) #, categorical_feature=cate_cols\n",
    "    va_data = lgb.Dataset(X_va, label=y_va) #, categorical_feature=cate_cols\n",
    "\n",
    "    model = lgb.train(parameters,\n",
    "                      tr_data,\n",
    "                      valid_sets=[tr_data,va_data],\n",
    "                      num_boost_round=8000,\n",
    "                      early_stopping_rounds=300,\n",
    "                      verbose_eval=100)\n",
    "    \n",
    "    yhat = model.predict(X_va, model.best_iteration)\n",
    "    scores.append(roc_auc_score(y_va,yhat))\n",
    "    print(ifold,roc_auc_score(y_va,yhat))\n",
    "    y_oof.loc[test_index,'target'] = yhat\n",
    "\n",
    "    print('prepare test')\n",
    "    \n",
    "    ytst = model.predict(X_te, model.best_iteration)\n",
    "    y_pred += ytst*0.1\n",
    "    \n",
    "    del X_tr,X_va,tr_data,va_data\n",
    "    gc.collect()    \n",
    "    \n",
    "    save_submit('lgb_q', ifold, y_pred)\n",
    "\n",
    "    ifold += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7031932260616095, 0.684053238540697, 0.67510996191806116, 0.69493612123727277, 0.68399008057849842, 0.68934470712390361, 0.68524272622684657, 0.69450546947435277, 0.68884208729959029, 0.69130655857097356]\n",
      "0.689052417703 0.00727359537567\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70101884559, 0.683251990687, 0.674342696529, 0.69439042338, 0.683629739895, 0.688567379887, 0.683618554598, 0.693767584936, 0.687560690599, 0.690429041143]\n",
      "0.688057694724 0.00705220902941\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "print(np.mean(score), np.std(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nn_all_in_one3'\n",
    "np.save(results_dir + 'train_' + model_name +'.npy', y_oof.target.values)\n",
    "sample_sub = pd.read_table(data_dir+'mlboot_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isnull? False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuid</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>888b238b4d14c03173baa375a739f6bc</td>\n",
       "      <td>0.689239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ac4b8244f3ae82df511b002257473c11</td>\n",
       "      <td>0.617930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483d8b91e49522c8a5bbe37f3872c749</td>\n",
       "      <td>0.701102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4c7ec46a0e88a7e1e1cedd2d526d5d61</td>\n",
       "      <td>0.505842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fdbfba9842ff0bf86d600eb334c7c42b</td>\n",
       "      <td>0.510307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               cuid    target\n",
       "0  888b238b4d14c03173baa375a739f6bc  0.689239\n",
       "1  ac4b8244f3ae82df511b002257473c11  0.617930\n",
       "2  483d8b91e49522c8a5bbe37f3872c749  0.701102\n",
       "3  4c7ec46a0e88a7e1e1cedd2d526d5d61  0.505842\n",
       "4  fdbfba9842ff0bf86d600eb334c7c42b  0.510307"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = x_te[['uid','target']].copy()\n",
    "sub['target'] = y_pred\n",
    "sub.columns = ['cuid','target']\n",
    "sample_sub = sample_sub.merge(sub, on='cuid', how='left')\n",
    "np.save(results_dir + 'test_' + model_name +'.npy', sample_sub.target.values)\n",
    "print('isnull?',sample_sub.target.isnull().any())\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub[['target']].to_csv(results_dir + model_name + '.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sol0</th>\n",
       "      <th>sol1</th>\n",
       "      <th>sol2</th>\n",
       "      <th>sol3</th>\n",
       "      <th>sol4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sol0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719971</td>\n",
       "      <td>0.681589</td>\n",
       "      <td>0.716230</td>\n",
       "      <td>0.709220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sol1</th>\n",
       "      <td>0.719971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826783</td>\n",
       "      <td>0.982878</td>\n",
       "      <td>0.975515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sol2</th>\n",
       "      <td>0.681589</td>\n",
       "      <td>0.826783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813299</td>\n",
       "      <td>0.819038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sol3</th>\n",
       "      <td>0.716230</td>\n",
       "      <td>0.982878</td>\n",
       "      <td>0.813299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sol4</th>\n",
       "      <td>0.709220</td>\n",
       "      <td>0.975515</td>\n",
       "      <td>0.819038</td>\n",
       "      <td>0.992501</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sol0      sol1      sol2      sol3      sol4\n",
       "sol0  1.000000  0.719971  0.681589  0.716230  0.709220\n",
       "sol1  0.719971  1.000000  0.826783  0.982878  0.975515\n",
       "sol2  0.681589  0.826783  1.000000  0.813299  0.819038\n",
       "sol3  0.716230  0.982878  0.813299  1.000000  0.992501\n",
       "sol4  0.709220  0.975515  0.819038  0.992501  1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "a = pd.DataFrame()\n",
    "a['sol0'] = minmax_scale(pd.read_csv(results_dir + 'nn_base_model.csv', header=None)[0].values)\n",
    "a['sol1'] = minmax_scale(pd.read_csv(results_dir + 'new_try.csv', header=None)[0].values)\n",
    "a['sol2'] = minmax_scale(pd.read_csv(results_dir + 'baseline_sparse_10folds.csv', header=None)[0].values)\n",
    "a['sol3'] = minmax_scale(pd.read_csv(results_dir + 'nn_all_in_one.csv', header=None)[0].values)\n",
    "a['sol4'] = minmax_scale(pd.read_csv(results_dir + 'nn_all_in_one2.csv', header=None)[0].values)\n",
    "a.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
